{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsc86/Processamento-de-Linguagem-Natural---PLN/blob/main/Aula_04_Extra%C3%A7%C3%A3o_de_caracter%C3%ADsticas_(features)_em_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 - Bow"
      ],
      "metadata": {
        "id": "5Wm0STpCLd_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a classe CountVectorizer do scikit-learn para criar representações numéricas de texto\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Corpus de documentos para treinamento\n",
        "documentos = [\n",
        "    \"gato e cachorro\",\n",
        "    \"gato brinca com cachorro\",\n",
        "    \"gato e rato\"\n",
        "]\n",
        "\n",
        "# 1. INICIALIZAÇÃO DO VETORIZADOR\n",
        "# Cria uma instância do CountVectorizer com parâmetros padrão\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# 2. TREINAMENTO E TRANSFORMAÇÃO\n",
        "# fit_transform realiza duas operações:\n",
        "# - fit: aprende o vocabulário a partir dos documentos\n",
        "# - transform: converte os textos em vetores numéricos\n",
        "X = vectorizer.fit_transform(documentos)\n",
        "\n",
        "# 3. VISUALIZAÇÃO DOS RESULTADOS\n",
        "print(\"\\n VOCABULÁRIO CRIADO:\")\n",
        "# vocabulary_ mostra o mapeamento palavra -> índice\n",
        "print(vectorizer.vocabulary_)\n",
        "\n",
        "print(\"\\n MATRIZ BAG-OF-WORDS:\")\n",
        "# toarray() converte a matriz esparsa para array denso\n",
        "print(X.toarray())\n",
        "\n",
        "# 4. INFORMAÇÕES ADICIONAIS\n",
        "print(\"\\n ESTATÍSTICAS:\")\n",
        "print(f\"Número de documentos: {X.shape[0]}\")\n",
        "print(f\"Tamanho do vocabulário: {X.shape[1]}\")\n",
        "print(\"\\nPalavras do vocabulário:\")\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNZAmgm2NGtd",
        "outputId": "d282c7d9-f064-413a-b394-e3e4fa7a5cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " VOCABULÁRIO CRIADO:\n",
            "{'gato': 3, 'cachorro': 1, 'brinca': 0, 'com': 2, 'rato': 4}\n",
            "\n",
            " MATRIZ BAG-OF-WORDS:\n",
            "[[0 1 0 1 0]\n",
            " [1 1 1 1 0]\n",
            " [0 0 0 1 1]]\n",
            "\n",
            " ESTATÍSTICAS:\n",
            "Número de documentos: 3\n",
            "Tamanho do vocabulário: 5\n",
            "\n",
            "Palavras do vocabulário:\n",
            "['brinca' 'cachorro' 'com' 'gato' 'rato']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. BOW com TF-IDF"
      ],
      "metadata": {
        "id": "mkZ0gpVCNsoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as classes para vetorização de texto\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Corpus de documentos para análise\n",
        "documentos = [\n",
        "    \"O cachorro gosta de passear no parque\",\n",
        "    \"O gato dorme no sofá o dia todo\",\n",
        "    \"Cachorros e gatos podem ser bons amigos\"\n",
        "]\n",
        "\n",
        "# 1. BAG-OF-WORDS (BoW) - CONTAGEM SIMPLES\n",
        "# ========================================\n",
        "\n",
        "# Cria e treina o vetorizador BoW\n",
        "bow_vectorizer = CountVectorizer()\n",
        "bow_matrix = bow_vectorizer.fit_transform(documentos)\n",
        "\n",
        "print(\"\\n BAG-OF-WORDS (BoW)\")\n",
        "print(\"---------------------\")\n",
        "print(f\"Vocabulário: {bow_vectorizer.vocabulary_}\")\n",
        "print(\"\\nMatriz de Contagem:\")\n",
        "print(bow_matrix.toarray())\n",
        "\n",
        "# 2. TF-IDF - FREQUÊNCIA PONDERADA\n",
        "# ================================\n",
        "\n",
        "# Cria e treina o vetorizador TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documentos)\n",
        "\n",
        "print(\"\\n TF-IDF (Term Frequency-Inverse Document Frequency)\")\n",
        "print(\"--------------------------------------------------\")\n",
        "print(f\"Vocabulário: {tfidf_vectorizer.vocabulary_}\")\n",
        "print(\"\\nMatriz TF-IDF:\")\n",
        "print(tfidf_matrix.toarray().round(2))  # Arredondado para 2 casas decimais\n",
        "\n",
        "# 3. COMPARAÇÃO ENTRE AS ABORDAGENS\n",
        "# =================================\n",
        "\n",
        "print(\"\\n COMPARAÇÃO:\")\n",
        "print(\"- BoW considera apenas a frequência bruta\")\n",
        "print(\"- TF-IDF pondera pela importância do termo no documento vs. no corpus\")\n",
        "print(\"- TF-IDF diminui peso de termos muito comuns (ex: 'o', 'de')\")\n",
        "\n",
        "# 4. INFORMAÇÕES ADICIONAIS\n",
        "# =========================\n",
        "\n",
        "print(\"\\n ESTATÍSTICAS:\")\n",
        "print(f\"Número de documentos: {bow_matrix.shape[0]}\")\n",
        "print(f\"Tamanho do vocabulário: {bow_matrix.shape[1]}\")\n",
        "print(\"\\nTermos mais importantes (TF-IDF):\")\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "for i, doc in enumerate(documentos):\n",
        "    print(f\"\\nDocumento {i+1}: '{doc}'\")\n",
        "    scores = tfidf_matrix[i].toarray().flatten()\n",
        "    important_terms = sorted(zip(feature_names, scores), key=lambda x: x[1], reverse=True)[:3]\n",
        "    for term, score in important_terms:\n",
        "        print(f\"  {term}: {score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixlb9ol6NzN9",
        "outputId": "915b2f9b-456e-4a39-b62e-f4e4be69e48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " BAG-OF-WORDS (BoW)\n",
            "---------------------\n",
            "Vocabulário: {'cachorro': 2, 'gosta': 9, 'de': 4, 'passear': 12, 'no': 10, 'parque': 11, 'gato': 7, 'dorme': 6, 'sofá': 15, 'dia': 5, 'todo': 16, 'cachorros': 3, 'gatos': 8, 'podem': 13, 'ser': 14, 'bons': 1, 'amigos': 0}\n",
            "\n",
            "Matriz de Contagem:\n",
            "[[0 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 1]\n",
            " [1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0]]\n",
            "\n",
            " TF-IDF (Term Frequency-Inverse Document Frequency)\n",
            "--------------------------------------------------\n",
            "Vocabulário: {'cachorro': 2, 'gosta': 9, 'de': 4, 'passear': 12, 'no': 10, 'parque': 11, 'gato': 7, 'dorme': 6, 'sofá': 15, 'dia': 5, 'todo': 16, 'cachorros': 3, 'gatos': 8, 'podem': 13, 'ser': 14, 'bons': 1, 'amigos': 0}\n",
            "\n",
            "Matriz TF-IDF:\n",
            "[[0.   0.   0.42 0.   0.42 0.   0.   0.   0.   0.42 0.32 0.42 0.42 0.\n",
            "  0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.42 0.42 0.42 0.   0.   0.32 0.   0.   0.\n",
            "  0.   0.42 0.42]\n",
            " [0.41 0.41 0.   0.41 0.   0.   0.   0.   0.41 0.   0.   0.   0.   0.41\n",
            "  0.41 0.   0.  ]]\n",
            "\n",
            " COMPARAÇÃO:\n",
            "- BoW considera apenas a frequência bruta\n",
            "- TF-IDF pondera pela importância do termo no documento vs. no corpus\n",
            "- TF-IDF diminui peso de termos muito comuns (ex: 'o', 'de')\n",
            "\n",
            " ESTATÍSTICAS:\n",
            "Número de documentos: 3\n",
            "Tamanho do vocabulário: 17\n",
            "\n",
            "Termos mais importantes (TF-IDF):\n",
            "\n",
            "Documento 1: 'O cachorro gosta de passear no parque'\n",
            "  cachorro: 0.42\n",
            "  de: 0.42\n",
            "  gosta: 0.42\n",
            "\n",
            "Documento 2: 'O gato dorme no sofá o dia todo'\n",
            "  dia: 0.42\n",
            "  dorme: 0.42\n",
            "  gato: 0.42\n",
            "\n",
            "Documento 3: 'Cachorros e gatos podem ser bons amigos'\n",
            "  amigos: 0.41\n",
            "  bons: 0.41\n",
            "  cachorros: 0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Word Embbeding utilizando Word2Vec"
      ],
      "metadata": {
        "id": "Taq-SvZbPcwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. PRIMEIRO LIMPAMOS AS INSTALAÇÕES CONFLITANTES\n",
        "!pip uninstall -y numpy gensim scipy\n",
        "\n",
        "# 2. INSTALAMOS AS VERSÕES COMPATÍVEIS\n",
        "!pip install numpy==1.23.5 gensim==4.3.2 scipy==1.9.3\n",
        "\n",
        "# 3. AGORA EXECUTAMOS O CÓDIGO WORD2VEC\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Corpus de exemplo\n",
        "corpus = [\n",
        "    [\"cachorro\", \"animal\", \"doméstico\"],\n",
        "    [\"gato\", \"animal\", \"doméstico\"],\n",
        "    [\"cachorro\", \"late\", \"osso\"],\n",
        "    [\"gato\", \"mia\", \"rato\"],\n",
        "    [\"animal\", \"veterinário\", \"clínica\"]\n",
        "]\n",
        "\n",
        "# Criando o modelo com parâmetros simplificados\n",
        "modelo = Word2Vec(\n",
        "    sentences=corpus,\n",
        "    vector_size=50,  # Dimensão reduzida para demonstração\n",
        "    window=3,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "# Testando o modelo\n",
        "print(\"Similaridade cachorro-gato:\", modelo.wv.similarity('cachorro', 'gato'))\n",
        "print(\"\\nPalavras similares a 'animal':\")\n",
        "for palavra, score in modelo.wv.most_similar('animal', topn=3):\n",
        "    print(f\"{palavra}: {score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "6OTzyEKnP7Tn",
        "outputId": "35299886-c60a-4ca8-b331-7b2d228f6dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Found existing installation: gensim 4.3.2\n",
            "Uninstalling gensim-4.3.2:\n",
            "  Successfully uninstalled gensim-4.3.2\n",
            "Found existing installation: scipy 1.9.3\n",
            "Uninstalling scipy-1.9.3:\n",
            "  Successfully uninstalled scipy-1.9.3\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting gensim==4.3.2\n",
            "  Using cached gensim-4.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Collecting scipy==1.9.3\n",
            "  Using cached scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==4.3.2) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim==4.3.2) (1.17.2)\n",
            "Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Using cached gensim-4.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.4 MB)\n",
            "Installing collected packages: numpy, scipy, gensim\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.9.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "cvxpy 1.6.4 requires scipy>=1.11.0, but you have scipy 1.9.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, but you have scipy 1.9.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.2 numpy-1.23.5 scipy-1.9.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "68affb7c2dc5460cb0c085316e7f1685"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similaridade cachorro-gato: -0.17424816\n",
            "\n",
            "Palavras similares a 'animal':\n",
            "mia: 0.132\n",
            "doméstico: 0.127\n",
            "late: 0.100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Corpus ampliado com mais contexto\n",
        "corpus = [\n",
        "    [\"o\", \"cachorro\", \"está\", \"latindo\", \"no\", \"quintal\"],\n",
        "    [\"o\", \"gato\", \"está\", \"miando\", \"no\", \"telhado\"],\n",
        "    [\"o\", \"pássaro\", \"está\", \"voando\", \"no\", \"céu\", \"lua\"],\n",
        "    [\"a\", \"bola\", \"está\", \"rolando\", \"no\", \"chão\"],\n",
        "    [\"a\", \"criança\", \"está\", \"brincando\", \"com\", \"o\", \"cachorro\"],\n",
        "    [\"o\", \"gato\", \"e\", \"o\", \"rato\", \"são\", \"inimigos\"],\n",
        "    [\"a\", \"água\", \"está\", \"quente\", \"na\", \"caneca\"],\n",
        "    [\"o\", \"sol\", \"está\", \"brilhando\", \"no\", \"céu\"],\n",
        "    [\"a\", \"lua\", \"está\", \"cheia\", \"hoje\", \"no\", \"céu\"],\n",
        "    [\"o\", \"computador\", \"está\", \"ligado\", \"na\", \"mesa\"],\n",
        "    [\"a\", \"lua\", \"está\", \"no\", \"céu\", \"lua\", \"bonita\"]\n",
        "]\n",
        "\n",
        "# Configuração do modelo\n",
        "model = Word2Vec(\n",
        "    sentences=corpus,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    sg=1,\n",
        "    workers=4\n",
        ")\n",
        "\n",
        "# Testando similaridades\n",
        "print(\"Similaridades semânticas:\")\n",
        "print(f\"cachorro-gato: {model.wv.similarity('cachorro', 'gato'):.3f}\")\n",
        "print(f\"cachorro-bola: {model.wv.similarity('cachorro', 'bola'):.3f}\")\n",
        "print(f\"céu-lua: {model.wv.similarity('céu', 'lua'):.3f}\")\n",
        "print(f\"computador-mesa: {model.wv.similarity('computador', 'mesa'):.3f}\")\n",
        "\n",
        "# Palavras mais similares\n",
        "print(\"\\nPalavras relacionadas:\")\n",
        "print(\"Para 'cachorro':\")\n",
        "for palavra, score in model.wv.most_similar('cachorro', topn=3):\n",
        "    print(f\"  {palavra}: {score:.3f}\")\n",
        "\n",
        "print(\"\\nPara 'céu':\")\n",
        "for palavra, score in model.wv.most_similar('céu', topn=3):\n",
        "    print(f\"  {palavra}: {score:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpOtUwsZTTEs",
        "outputId": "04f2b8c6-bfc0-4aca-c77d-62ea6fe7a363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similaridades semânticas:\n",
            "cachorro-gato: 0.009\n",
            "cachorro-bola: -0.121\n",
            "céu-lua: 0.139\n",
            "computador-mesa: 0.050\n",
            "\n",
            "Palavras relacionadas:\n",
            "Para 'cachorro':\n",
            "  quente: 0.285\n",
            "  no: 0.199\n",
            "  mesa: 0.097\n",
            "\n",
            "Para 'céu':\n",
            "  telhado: 0.167\n",
            "  inimigos: 0.163\n",
            "  lua: 0.139\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsc86/Processamento-de-Linguagem-Natural---PLN/blob/main/A_12_13_Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Rede Neural de Recorrência"
      ],
      "metadata": {
        "id": "jFMss914T1uE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- Configuração do Colab"
      ],
      "metadata": {
        "id": "tRHqhMPFT9an"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeGYmSbfTv2G",
        "outputId": "37721193-a10b-4f45-fb50-6e9007df7304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Preparação dos dados"
      ],
      "metadata": {
        "id": "oDjGU78OUFQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textos_treinamento = [\n",
        "  \"eu gosto de programar em python\",\n",
        "  \"python e uma linguagem poderosa\",\n",
        "  \"programar é divertido com python\",\n",
        "  \"aprenda python e seja feliz\",\n",
        "  \"gosto de aprender coisas novas\"\n",
        "]\n",
        "\n",
        "print(f\"Textos de treinamento: {textos_treinamento}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrIkIh-ZUJdS",
        "outputId": "509f51d8-16de-4454-bc43-51c5f1435eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Textos de treinamento: ['eu gosto de programar em python', 'python e uma linguagem poderosa', 'programar é divertido com python', 'aprenda python e seja feliz', 'gosto de aprender coisas novas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(textos_treinamento)\n",
        "\n",
        "sequencias = tokenizer.texts_to_sequences(textos_treinamento)\n",
        "\n",
        "print(f\"\\nVocabulario (palavra: indice): {tokenizer.word_index}\")\n",
        "print(f\"Sequências numéricas dos textos: {sequencias}\")\n",
        "\n",
        "# +1 para incluir o 0 de padding\n",
        "total_palavras = len(tokenizer.word_index) + 1\n",
        "print (f\"Tamanho total do vocabulario: {total_palavras}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiZ6TbM0UPGj",
        "outputId": "99f81a67-93ea-4568-d5f7-305af858de4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulario (palavra: indice): {'python': 1, 'gosto': 2, 'de': 3, 'programar': 4, 'e': 5, 'eu': 6, 'em': 7, 'uma': 8, 'linguagem': 9, 'poderosa': 10, 'é': 11, 'divertido': 12, 'com': 13, 'aprenda': 14, 'seja': 15, 'feliz': 16, 'aprender': 17, 'coisas': 18, 'novas': 19}\n",
            "Sequências numéricas dos textos: [[6, 2, 3, 4, 7, 1], [1, 5, 8, 9, 10], [4, 11, 12, 13, 1], [14, 1, 5, 15, 16], [2, 3, 17, 18, 19]]\n",
            "Tamanho total do vocabulario: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_comprimento = max(len(seq) for seq in sequencias)\n",
        "print(f\"\\nComprimento máximo das sequências antes do padding: {max_comprimento}\")\n",
        "\n",
        "entradas_x = []\n",
        "saidas_y = []\n",
        "\n",
        "for seq in sequencias:\n",
        "  for i in range(1, len(seq)):\n",
        "    entradas_x.append(seq[:i])\n",
        "    saidas_y.append(seq[i])\n",
        "\n",
        "print(f\"Exemplo de entradas_X (parcial): {entradas_x[0:5]}\")\n",
        "print(f\"Exemplo de saidas_y (parcial): {saidas_y[0:5]}\")\n",
        "\n",
        "entradas_X_padded = pad_sequences(entradas_x, maxlen=max_comprimento -1, padding='pre')\n",
        "saidas_y_one_hot = tf.keras.utils.to_categorical(saidas_y, num_classes=total_palavras)\n",
        "\n",
        "print(f\"\\nExemplo de entradas_x padded (apos padding e truncagem): \\n{entradas_X_padded[0:5]}\")\n",
        "print(f\"Exemplo de saidas_y_one_hot (apos one-hot encoding): \\n{saidas_y_one_hot[0:5]}\")\n",
        "print(f\"Formato final das entradas (X): {entradas_X_padded.shape}\")\n",
        "print(f\"Formato final das saidas (y): {saidas_y_one_hot. shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJU12TxiURqX",
        "outputId": "d855016e-a320-4a5b-ad08-2fa6dc9fc6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comprimento máximo das sequências antes do padding: 6\n",
            "Exemplo de entradas_X (parcial): [[6], [6, 2], [6, 2, 3], [6, 2, 3, 4], [6, 2, 3, 4, 7]]\n",
            "Exemplo de saidas_y (parcial): [2, 3, 4, 7, 1]\n",
            "\n",
            "Exemplo de entradas_x padded (apos padding e truncagem): \n",
            "[[0 0 0 0 6]\n",
            " [0 0 0 6 2]\n",
            " [0 0 6 2 3]\n",
            " [0 6 2 3 4]\n",
            " [6 2 3 4 7]]\n",
            "Exemplo de saidas_y_one_hot (apos one-hot encoding): \n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Formato final das entradas (X): (21, 5)\n",
            "Formato final das saidas (y): (21, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_comprimento = max(len(seq) for seq in sequencias)\n",
        "print(f\"\\nComprimento máximo das sequências antes do padding: {max_comprimento}\")\n",
        "\n",
        "entradas_x = []\n",
        "saidas_y = []\n",
        "\n",
        "for seq in sequencias:\n",
        "  for i in range(1, len(seq)):\n",
        "    entradas_x.append(seq[:i])\n",
        "    saidas_y.append(seq[i])\n",
        "\n",
        "print(f\"Exemplo de entradas_X (parcial): {entradas_x[0:5]}\")\n",
        "print(f\"Exemplo de saidas_y (parcial): {saidas_y[0:5]}\")\n",
        "\n",
        "entradas_X_padded = pad_sequences(entradas_x, maxlen=max_comprimento -1, padding='pre')\n",
        "saidas_y_one_hot = tf.keras.utils.to_categorical(saidas_y, num_classes=total_palavras)\n",
        "\n",
        "print(f\"\\nExemplo de entradas_x padded (apos padding e truncagem): \\n{entradas_X_padded[0:5]}\")\n",
        "print(f\"Exemplo de saidas_y_one_hot (apos one-hot encoding): \\n{saidas_y_one_hot[0:5]}\")\n",
        "print(f\"Formato final das entradas (X): {entradas_X_padded.shape}\")\n",
        "print(f\"Formato final das saidas (y): {saidas_y_one_hot. shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-JtDJ18UU-F",
        "outputId": "04d04f87-6f87-450b-f071-3774c5d35946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comprimento máximo das sequências antes do padding: 6\n",
            "Exemplo de entradas_X (parcial): [[6], [6, 2], [6, 2, 3], [6, 2, 3, 4], [6, 2, 3, 4, 7]]\n",
            "Exemplo de saidas_y (parcial): [2, 3, 4, 7, 1]\n",
            "\n",
            "Exemplo de entradas_x padded (apos padding e truncagem): \n",
            "[[0 0 0 0 6]\n",
            " [0 0 0 6 2]\n",
            " [0 0 6 2 3]\n",
            " [0 6 2 3 4]\n",
            " [6 2 3 4 7]]\n",
            "Exemplo de saidas_y_one_hot (apos one-hot encoding): \n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Formato final das entradas (X): (21, 5)\n",
            "Formato final das saidas (y): (21, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Construção do RNN"
      ],
      "metadata": {
        "id": "n6CFuK-VUYSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_rnn = Sequential()\n",
        "\n",
        "modelo_rnn.add(Embedding(total_palavras, 10, input_length=entradas_X_padded.shape[1]))\n",
        "modelo_rnn.add(SimpleRNN(32))\n",
        "modelo_rnn.add(Dense(total_palavras, activation='softmax' ))\n",
        "\n",
        "modelo_rnn. compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "modelo_rnn.summary ()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "scKAEccFUagR",
        "outputId": "b0c050bd-8e6b-470d-839e-ddb9566a74e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Treinamento do modelo"
      ],
      "metadata": {
        "id": "dqUzXrmjUc80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nIniciando o treinamento do modelo RNN ... \")\n",
        "modelo_rnn.fit(entradas_X_padded, saidas_y_one_hot, epochs=100, verbose=1)\n",
        "print(\"Treinamento concluído!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW6GIDi0Uf5Z",
        "outputId": "b2cd0939-9eeb-4ad9-c478-dd73b10e36fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento do modelo RNN ... \n",
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.1429 - loss: 2.9845\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1429 - loss: 2.9748\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1905 - loss: 2.9650\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1905 - loss: 2.9550\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2381 - loss: 2.9448\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2857 - loss: 2.9343\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.2857 - loss: 2.9235\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2857 - loss: 2.9125\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2857 - loss: 2.9011\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2857 - loss: 2.8893\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2857 - loss: 2.8772\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2381 - loss: 2.8648\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2381 - loss: 2.8520\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2381 - loss: 2.8388\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2381 - loss: 2.8253\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2381 - loss: 2.8115\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2381 - loss: 2.7975\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2381 - loss: 2.7834\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2381 - loss: 2.7690\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2381 - loss: 2.7547\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2381 - loss: 2.7403\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2381 - loss: 2.7259\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2381 - loss: 2.7116\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2381 - loss: 2.6974\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2381 - loss: 2.6832\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2381 - loss: 2.6689\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2381 - loss: 2.6546\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2381 - loss: 2.6400\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2381 - loss: 2.6252\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2381 - loss: 2.6101\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2381 - loss: 2.5946\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2381 - loss: 2.5787\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2381 - loss: 2.5623\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2381 - loss: 2.5454\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2381 - loss: 2.5281\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2857 - loss: 2.5103\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2857 - loss: 2.4921\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3333 - loss: 2.4733\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3333 - loss: 2.4541\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3810 - loss: 2.4343\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.3810 - loss: 2.4141\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3810 - loss: 2.3933\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3810 - loss: 2.3720\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.3810 - loss: 2.3502\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3810 - loss: 2.3279\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3810 - loss: 2.3051\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3810 - loss: 2.2818\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3810 - loss: 2.2582\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4286 - loss: 2.2341\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4286 - loss: 2.2097\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3810 - loss: 2.1851\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3810 - loss: 2.1602\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3810 - loss: 2.1351\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3810 - loss: 2.1098\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3810 - loss: 2.0843\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4286 - loss: 2.0588\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4286 - loss: 2.0331\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4286 - loss: 2.0074\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4286 - loss: 1.9817\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4286 - loss: 1.9560\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4286 - loss: 1.9304\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4762 - loss: 1.9049\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5238 - loss: 1.8795\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5238 - loss: 1.8542\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5238 - loss: 1.8292\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5714 - loss: 1.8043\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5714 - loss: 1.7797\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5714 - loss: 1.7553\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5714 - loss: 1.7312\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5714 - loss: 1.7073\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6190 - loss: 1.6838\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6190 - loss: 1.6605\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6190 - loss: 1.6375\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6190 - loss: 1.6148\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6190 - loss: 1.5924\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6190 - loss: 1.5704\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6190 - loss: 1.5486\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6190 - loss: 1.5271\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6190 - loss: 1.5059\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6667 - loss: 1.4849\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7143 - loss: 1.4643\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7143 - loss: 1.4439\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7143 - loss: 1.4237\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7619 - loss: 1.4039\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7619 - loss: 1.3842\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8095 - loss: 1.3648\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8095 - loss: 1.3456\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8571 - loss: 1.3266\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8571 - loss: 1.3077\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8571 - loss: 1.2891\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8571 - loss: 1.2707\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8571 - loss: 1.2525\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8571 - loss: 1.2344\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.8571 - loss: 1.2165\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8571 - loss: 1.1988\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8571 - loss: 1.1813\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8571 - loss: 1.1639\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8571 - loss: 1.1467\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8571 - loss: 1.1297\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8571 - loss: 1.1128\n",
            "Treinamento concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5- Modelo de previsão"
      ],
      "metadata": {
        "id": "uVkAS1c1UlqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prever_proxima_palavra(modelo, tokenizer, max_seq_len, texto_base):\n",
        "  sequencia_numerica = tokenizer.texts_to_sequences([texto_base])[0]\n",
        "\n",
        "  sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='pre')\n",
        "  previsao_probabilidades = modelo.predict(sequencia_padded, verbose=0)[0]\n",
        "\n",
        "  indice_palavra_prevista = np.argmax(previsao_probabilidades)\n",
        "\n",
        "  for palavra, indice in tokenizer.word_index.items():\n",
        "    if indice == indice_palavra_prevista:\n",
        "      return palavra\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "comprimento_entrada_modelo = entradas_X_padded. shape[1]\n",
        "\n",
        "print(\"\\n --- Testando o Modelo RNN --- \")\n",
        "\n",
        "texto_teste_1 = \"eu gosto de\"\n",
        "proxima_1 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_1)\n",
        "print(f\"Texto: '{texto_teste_1}' -> Proxima palavra prevista: '{proxima_1}'\")\n",
        "\n",
        "texto_teste_2 = \"python é uma\"\n",
        "proxima_2 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_2)\n",
        "print(f\"Texto: '{texto_teste_2}' -> Proxima palavra prevista: '{proxima_2}'\")\n",
        "\n",
        "texto_teste_3 = \"programar é divertido\"\n",
        "proxima_3 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_3)\n",
        "print(f\"Texto: '{texto_teste_3}' -> Proxima palavra prevista: '{proxima_3}'\")\n",
        "\n",
        "texto_teste_4 = \"aprenda python e\"\n",
        "proxima_4 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_4)\n",
        "print(f\"Texto: '{texto_teste_4}' -> Proxima palavra prevista: '{proxima_4}'\")\n",
        "\n",
        "texto_teste_5 = \"o sol brilha no\" # \"sol\" e \"brilha\" NÃO estão no vocábulario\n",
        "proxima_5 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_5)\n",
        "print(f\"Texto: '{texto_teste_5}' -> Proxima palavra prevista: '{proxima_5}' (Pode ser inesperada devido a palavras desconhecidas)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rC10quJUnRC",
        "outputId": "405e722a-d41b-439f-beba-54d8bade9a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " --- Testando o Modelo RNN --- \n",
            "Texto: 'eu gosto de' -> Proxima palavra prevista: 'programar'\n",
            "Texto: 'python é uma' -> Proxima palavra prevista: 'linguagem'\n",
            "Texto: 'programar é divertido' -> Proxima palavra prevista: 'com'\n",
            "Texto: 'aprenda python e' -> Proxima palavra prevista: 'seja'\n",
            "Texto: 'o sol brilha no' -> Proxima palavra prevista: 'python' (Pode ser inesperada devido a palavras desconhecidas)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Rede Neural Rede Long Short-Term Memory"
      ],
      "metadata": {
        "id": "IMOxUxcaUtWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- Configuração e import de bibliotecas"
      ],
      "metadata": {
        "id": "3sWCn9CFUyeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras. preprocessing. sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Reg8-oypUxna",
        "outputId": "9bc95576-6980-433d-b87c-a2b41683710a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Preparação e análise de sentimentos"
      ],
      "metadata": {
        "id": "cQYi5odHU5LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados_sentimento = [\n",
        "  (\"este filme é ótimo e divertido\", \"positivo\"),\n",
        "  (\"eu adorei o livro, muito bom\", \"positivo\"),\n",
        "  (\"gostei muito da atuação dos atores\", \"positivo\"),\n",
        "  (\"o roteiro é fraco e chato\", \"negativo\"),\n",
        "  (\"não recomendo este péssimo produto\", \"negativo\"),\n",
        "  (\"uma perda de tempo horrivel\", \"negativo\"),\n",
        "  (\"otimo trabalho, parabens\", \"positivo\"),\n",
        "  (\"terrível experiência, nunca mais\", \"negativo\"),\n",
        "  (\"excelente serviço, muito eficiente\", \"positivo\"),\n",
        "  (\"que decepção, muito ruim\", \"negativo\"),\n",
        "  (\"aprendizagem de máquina é fascinante\", \"positivo\"),\n",
        "  (\"pln é um campo interessante\", \"positivo\"),\n",
        "  (\"este software travou várias vezes\", \"negativo\"),\n",
        "  (\"a interface é confusa e difícil\", \"negativo\"),\n",
        "  (\"o aplicativo é super útil e rápido\", \"positivo\"),\n",
        "]\n",
        "\n",
        "textos = [dado[0] for dado in dados_sentimento]\n",
        "sentimentos = [dado[1] for dado in dados_sentimento]\n",
        "\n",
        "print(f\"Total de frases: {len(textos)}\")\n",
        "print(f\"Exemplo de textos: {textos[:3]}\")\n",
        "print(f\"Exemplo de sentimentos: {sentimentos[:3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syklTPMZU7kK",
        "outputId": "872e4a39-6862-4610-d8b2-9c1dbbfbdf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de frases: 15\n",
            "Exemplo de textos: ['este filme é ótimo e divertido', 'eu adorei o livro, muito bom', 'gostei muito da atuação dos atores']\n",
            "Exemplo de sentimentos: ['positivo', 'positivo', 'positivo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapear Sentimentos\n",
        "mapeamento_sentimento = {'negativo': 0, 'positivo': 1}\n",
        "rotulos_numericos = np.array([mapeamento_sentimento[s] for s in sentimentos])\n",
        "\n",
        "print(f\"\\nSentimentos mapeados para números: {rotulos_numericos}\")\n",
        "\n",
        "tokenizer = Tokenizer(num_words=None, oov_token=\"\")\n",
        "\n",
        "tokenizer.fit_on_texts(textos)\n",
        "sequencias_numericas = tokenizer.texts_to_sequences(textos)\n",
        "\n",
        "total_palavras_vocab = len(tokenizer.word_index) + 1 # +1 para o 0 de padding/oov\n",
        "\n",
        "print(f\"\\nvocabulário (palavra: índice): {tokenizer.word_index}\")\n",
        "print(f\"Sequências numéricas das frases: {sequencias_numericas}\")\n",
        "print(f\"Tamanho total do vocabulario: {total_palavras_vocab}\")\n",
        "\n",
        "#Encontrar o comprimento da frase mais longa para padronizar\n",
        "max_len = max(len(s) for s in sequencias_numericas)\n",
        "print(f\"\\nComprimento máximo das sequências: {max_len}\")\n",
        "\n",
        "sequencias_padded = pad_sequences(sequencias_numericas, maxlen=max_len, padding='post') # 'post' para adicionar zeros no final\n",
        "print(f\"Sequências apos padding: \\n{sequencias_padded}\")\n",
        "\n",
        "#Dividir os dados em conjuntos de treinamento e teste\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "  sequencias_padded, rotulos_numericos, test_size=0.2, random_state=42, stratify=rotulos_numericos\n",
        ")\n",
        "\n",
        "print(f\"\\nShape de x_treino: {X_treino.shape}\")\n",
        "print(f\"Shape de X_teste: {X_teste.shape}\")\n",
        "print(f\"Shape de y_treino: {y_treino.shape}\")\n",
        "print(f\"Shape de y_teste: {y_teste.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEEnvxpCU-20",
        "outputId": "875b5f09-0bf4-4f81-8045-8ed7b10b3d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentimentos mapeados para números: [1 1 1 0 0 0 1 0 1 0 1 1 0 0 1]\n",
            "\n",
            "vocabulário (palavra: índice): {'': 1, 'é': 2, 'e': 3, 'muito': 4, 'este': 5, 'o': 6, 'de': 7, 'filme': 8, 'ótimo': 9, 'divertido': 10, 'eu': 11, 'adorei': 12, 'livro': 13, 'bom': 14, 'gostei': 15, 'da': 16, 'atuação': 17, 'dos': 18, 'atores': 19, 'roteiro': 20, 'fraco': 21, 'chato': 22, 'não': 23, 'recomendo': 24, 'péssimo': 25, 'produto': 26, 'uma': 27, 'perda': 28, 'tempo': 29, 'horrivel': 30, 'otimo': 31, 'trabalho': 32, 'parabens': 33, 'terrível': 34, 'experiência': 35, 'nunca': 36, 'mais': 37, 'excelente': 38, 'serviço': 39, 'eficiente': 40, 'que': 41, 'decepção': 42, 'ruim': 43, 'aprendizagem': 44, 'máquina': 45, 'fascinante': 46, 'pln': 47, 'um': 48, 'campo': 49, 'interessante': 50, 'software': 51, 'travou': 52, 'várias': 53, 'vezes': 54, 'a': 55, 'interface': 56, 'confusa': 57, 'difícil': 58, 'aplicativo': 59, 'super': 60, 'útil': 61, 'rápido': 62}\n",
            "Sequências numéricas das frases: [[5, 8, 2, 9, 3, 10], [11, 12, 6, 13, 4, 14], [15, 4, 16, 17, 18, 19], [6, 20, 2, 21, 3, 22], [23, 24, 5, 25, 26], [27, 28, 7, 29, 30], [31, 32, 33], [34, 35, 36, 37], [38, 39, 4, 40], [41, 42, 4, 43], [44, 7, 45, 2, 46], [47, 2, 48, 49, 50], [5, 51, 52, 53, 54], [55, 56, 2, 57, 3, 58], [6, 59, 2, 60, 61, 3, 62]]\n",
            "Tamanho total do vocabulario: 63\n",
            "\n",
            "Comprimento máximo das sequências: 7\n",
            "Sequências apos padding: \n",
            "[[ 5  8  2  9  3 10  0]\n",
            " [11 12  6 13  4 14  0]\n",
            " [15  4 16 17 18 19  0]\n",
            " [ 6 20  2 21  3 22  0]\n",
            " [23 24  5 25 26  0  0]\n",
            " [27 28  7 29 30  0  0]\n",
            " [31 32 33  0  0  0  0]\n",
            " [34 35 36 37  0  0  0]\n",
            " [38 39  4 40  0  0  0]\n",
            " [41 42  4 43  0  0  0]\n",
            " [44  7 45  2 46  0  0]\n",
            " [47  2 48 49 50  0  0]\n",
            " [ 5 51 52 53 54  0  0]\n",
            " [55 56  2 57  3 58  0]\n",
            " [ 6 59  2 60 61  3 62]]\n",
            "\n",
            "Shape de x_treino: (12, 7)\n",
            "Shape de X_teste: (3, 7)\n",
            "Shape de y_treino: (12,)\n",
            "Shape de y_teste: (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Construção do LSTM"
      ],
      "metadata": {
        "id": "HskiAUqiVCBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_lstm = Sequential()\n",
        "\n",
        "modelo_lstm.add(Embedding(total_palavras_vocab, 50, input_length=max_len))\n",
        "\n",
        "#Camada LSTM:\n",
        "modelo_lstm.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "modelo_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "modelo_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "modelo_lstm. summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "dWLY_0TYVDpC",
        "outputId": "5d91a51c-12b5-4e74-8372-08eac8246f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Treinamento e avaliação"
      ],
      "metadata": {
        "id": "WYONANiTVIy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nIniciando o treinamento do modelo LSTM ... \")\n",
        "\n",
        "historico = modelo_lstm.fit(\n",
        "  X_treino, y_treino,\n",
        "  epochs=50,\n",
        "  batch_size=2,\n",
        "  validation_split=0.1,\n",
        "  verbose=1\n",
        ")\n",
        "\n",
        "#epochs: número de vezes que o modelo verá todo o conjunto de dados de treinamento.\n",
        "#batch_size: número de amostras por atualização de gradiente.\n",
        "#validation_split: % dos dados de treino usados para validacao durante o treinamento (opcional, mas bom para monitorar overfitting)\n",
        "\n",
        "print(\"Treinamento concluido!\")\n",
        "\n",
        "perda, acuracia = modelo_lstm.evaluate(X_teste, y_teste, verbose=0)\n",
        "print(f\"\\nAcuracia do modelo no conjunto de teste: {acuracia*100:.2f}%\")\n",
        "print(f\"Perda do modelo no conjunto de teste: {perda:.4f}\")\n",
        "\n",
        "y_pred_prob = modelo_lstm.predict(X_teste)\n",
        "y_pred_classes = (y_pred_prob > 0.5).astype(int) #Converter probabilidades para 0 ou 1\n",
        "\n",
        "print(\"\\n --- Relatório de Classificação --- \")\n",
        "print(classification_report(y_teste, y_pred_classes, target_names=['negativo', 'positivo' ]))\n",
        "\n",
        "print(\"\\n --- Matriz de Confusão --- \")\n",
        "cm = confusion_matrix(y_teste, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['negativo', 'positivo' ], yticklabels=['negativo', 'positivo' ])\n",
        "plt.xlabel('Previsto')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusao')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EwcgKtwCVLAu",
        "outputId": "b97189d9-b357-405a-cfc8-c80143183ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento do modelo LSTM ... \n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 4.9814e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.5918\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.6069e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.6142\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.2752e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.6344\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.0372e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.6568\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.9499e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.6803\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.8877e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.7022\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.3459e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.7187\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.0743e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.7349\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.9890e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.7542\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.0290e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.7683\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.6886e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.7822\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.0108e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.7995\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.8598e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.8180\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 4.9934e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.8394\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.0393e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.8559\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.1152e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.8756\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.5322e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.8956\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.5070e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.9131\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.8783e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.9294\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.6583e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.9455\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.8467e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.9614\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.3753e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.9779\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.9178e-04 - val_accuracy: 0.0000e+00 - val_loss: 4.9971\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1408e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.0120\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.0486e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.0270\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.6465e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.0418\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.5073e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.0580\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.7745e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.0735\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.5120e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.0907\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.4845e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.1054\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 2.2803e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.1218\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.0162e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.1353\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 3.4893e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.1506\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1988e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.1633\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.8278e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.1777\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.1635e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.1905\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.6862e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2044\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.5456e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2166\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 2.0207e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2296\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.6269e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2436\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.4963e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2548\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 2.9584e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2701\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 1.4813e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2818\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 1.4892e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.2920\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.7570e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3027\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4751e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3135\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.5053e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3236\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3737e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3328\n",
            "Epoch 49/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.0978e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3425\n",
            "Epoch 50/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.4220e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.3532\n",
            "Treinamento concluido!\n",
            "\n",
            "Acuracia do modelo no conjunto de teste: 66.67%\n",
            "Perda do modelo no conjunto de teste: 1.6151\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\n",
            " --- Relatório de Classificação --- \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.50      1.00      0.67         1\n",
            "    positivo       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.75      0.75      0.67         3\n",
            "weighted avg       0.83      0.67      0.67         3\n",
            "\n",
            "\n",
            " --- Matriz de Confusão --- \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5- Testando o modelo com novas frases"
      ],
      "metadata": {
        "id": "r-QPxvbfVhks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prever_sentimento(modelo, tokenizer, max_seq_len, frase_nova, mapeamento_sentimento):\n",
        "  sequencia_numerica = tokenizer.texts_to_sequences([frase_nova])\n",
        "\n",
        "  if not sequencia_numerica:\n",
        "    print(f\"Aviso: A frase '{frase_nova}' contem apenas palavras desconhecidas.\")\n",
        "    return \"Desconhecido\"\n",
        "\n",
        "  sequencia_numerica = sequencia_numerica[0]\n",
        "\n",
        "  sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='post')\n",
        "\n",
        "  probabilidade_positiva = modelo.predict(sequencia_padded, verbose=0)[0][0]\n",
        "\n",
        "  mapeamento_inverso = {v: k for k, v in mapeamento_sentimento.items()}\n",
        "\n",
        "  #Classificar com base no limiar de 0.5\n",
        "  if probabilidade_positiva >= 0.5:\n",
        "    return mapeamento_inverso[1] # 'positivo'\n",
        "  else:\n",
        "    return mapeamento_inverso[0] # 'negativo'\n",
        "\n",
        "print(\"\\n --- Testando o Modelo LSTM com Novas Frases --- \")\n",
        "\n",
        "frase_nova_1 = \"gostei muito do filme, excelente!\"\n",
        "sentimento_1 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_1, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_1}' -> Sentimento previsto: '{sentimento_1}'\")\n",
        "\n",
        "frase_nova_2 = \"odiei o livro, muito entediante\"\n",
        "sentimento_2 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_2, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_2}' -> Sentimento previsto: ' {sentimento_2}'\")\n",
        "\n",
        "frase_nova_3 = \"a aula de pln é ótima\"\n",
        "sentimento_3 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_3, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_3}' -> Sentimento previsto: '{sentimento_3}'\")\n",
        "\n",
        "frase_nova_4 = \"o atendimento foi péssimo\"\n",
        "sentimento_4 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_4, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_4}' -> Sentimento previsto: '{sentimento_4}'\")\n",
        "\n",
        "frase_nova_5 = \"esse produto não vale a pena, é caro\"\n",
        "sentimento_5 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_5, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_5}' -> Sentimento previsto: '{sentimento_5}'\")\n",
        "\n",
        "frase_nova_6 = \"o filme é legal\" #Frase curta e ambígua para um modelo pequeno\n",
        "sentimento_6 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_6, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_6}' -> Sentimento previsto: ' {sentimento_6}'\")\n",
        "\n",
        "frase_nova_7 = \"isso é horrível, que tristeza\"\n",
        "sentimento_7 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_7, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_7}' -> Sentimento previsto: '{sentimento_7}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0nRO9lEVkNq",
        "outputId": "aad65a4c-e2f9-4ed9-e749-9dcf41719f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " --- Testando o Modelo LSTM com Novas Frases --- \n",
            "Frase: 'gostei muito do filme, excelente!' -> Sentimento previsto: 'positivo'\n",
            "Frase: 'odiei o livro, muito entediante' -> Sentimento previsto: ' positivo'\n",
            "Frase: 'a aula de pln é ótima' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'o atendimento foi péssimo' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'esse produto não vale a pena, é caro' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'o filme é legal' -> Sentimento previsto: ' negativo'\n",
            "Frase: 'isso é horrível, que tristeza' -> Sentimento previsto: 'negativo'\n"
          ]
        }
      ]
    }
  ]
}